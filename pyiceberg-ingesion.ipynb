{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from kafka.errors import NoBrokersAvailable\n",
    "import json\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'my_topic'\n",
    "bootstrap_servers = ['kafka_url:443']\n",
    "group_id = 'mygroup'\n",
    "# SSL Configuration\n",
    "ssl_certfile = './sslcert.crt'\n",
    "ssl_cafile = './sslcert.pem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = None\n",
    "try:\n",
    "        # Create KafkaConsumer\n",
    "        consumer = KafkaConsumer(\n",
    "            topic,\n",
    "            bootstrap_servers=bootstrap_servers,\n",
    "            value_deserializer=lambda v: v,  # Keep value as bytes for JSON decoding\n",
    "            group_id=group_id,\n",
    "            auto_offset_reset='earliest',\n",
    "            consumer_timeout_ms=20000,\n",
    "            security_protocol='SSL',  # Add SSL configuration if needed\n",
    "            ssl_cafile=ssl_cafile,\n",
    "            ssl_certfile=ssl_certfile\n",
    "        )\n",
    "        logger.info(\"Successfully connected to Kafka broker\")\n",
    "except NoBrokersAvailable as e:\n",
    "    logger.error(f\"No brokers available. Ensure the Kafka broker is running and accessible. Error: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create Kafka consumer. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_messages(consumer):\n",
    "    messages = []\n",
    "    try:\n",
    "        logger.info(\"Starting message consumption\")\n",
    "        for message in consumer:\n",
    "            logger.debug(f\"Consumed message: {message.value}\")\n",
    "            json_message = json.loads(message.value.decode('utf-8'))  # Decode and parse JSON\n",
    "            messages.append(json_message)\n",
    "            if(messages.length == 2) :\n",
    "                consumer.close()\n",
    "                logger.info(f\"Consumed {messages.length} messages\")\n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Stopping consumer...\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        consumer.close()\n",
    "        logger.info(\"Consumer closed\")\n",
    "        print(messages)\n",
    "        \n",
    "    return messages\n",
    "consume_messages(consumer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import ClientError\n",
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.exceptions import NamespaceAlreadyExistsError\n",
    "from pyiceberg.schema import Schema, NestedField\n",
    "from pyiceberg.types import StringType, LongType\n",
    "from pyiceberg.partitioning import PartitionSpec, PartitionField\n",
    "from pyiceberg.table.sorting import SortOrder, SortField,IdentityTransform\n",
    "from pyiceberg.transforms import DayTransform, IdentityTransform\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_s3_bucket(bucket_name, minio_endpoint, access_key, secret_key):\n",
    "    try:\n",
    "        s3 = boto3.client('s3',\n",
    "                          endpoint_url=minio_endpoint,\n",
    "                          aws_access_key_id=access_key,\n",
    "                          aws_secret_access_key=secret_key,\n",
    "                          config=Config(signature_version='s3v4'))\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "        logger.info(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou':\n",
    "            logger.info(f\"Bucket '{bucket_name}' already exists and is owned by you.\")\n",
    "        elif e.response['Error']['Code'] == 'BucketAlreadyExists':\n",
    "            logger.info(f\"Bucket '{bucket_name}' already exists.\")\n",
    "        elif e.response['Error']['Code'] == 'AccessDenied':\n",
    "            logger.error(f\"Access denied to create bucket '{bucket_name}'.\")\n",
    "        else:\n",
    "            logger.error(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "def setup_iceberg_table():\n",
    "    s3_bucket_name = \"my_buket_name\"\n",
    "    minio_endpoint = 'http://minio-url:8080'\n",
    "    access_key = 'minio123'\n",
    "    secret_key = 'minio123'\n",
    "\n",
    "    # Create the bucket first\n",
    "    create_s3_bucket(s3_bucket_name, minio_endpoint, access_key, secret_key)\n",
    "\n",
    "    try:\n",
    "        catalog = load_catalog(\n",
    "            \"hive\",\n",
    "            **{\n",
    "                \"uri\": \"thrift://hive_url:9083\",\n",
    "                \"s3.endpoint\": minio_endpoint,\n",
    "                \"py-io-impl\": \"pyiceberg.io.pyarrow.PyArrowFileIO\",\n",
    "                \"s3.access-key-id\": access_key,\n",
    "                \"s3.secret-access-key\": secret_key\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Check if namespace exists before creating it\n",
    "        namespaces = catalog.list_namespaces()\n",
    "        # if \"powerlevelpoddata\" not in namespaces:\n",
    "        #     catalog.create_namespace(\"powerlevelpoddata\")\n",
    "        #     logger.info(\"Namespace 'powerlevelpoddata' created successfully.\")\n",
    "        # else:\n",
    "        #     logger.info(\"Namespace 'powerlevelpoddata' already exists.\")\n",
    "\n",
    "        schema = Schema(\n",
    "            NestedField(field_id=1, name=\"resourceMetrics\", field_type=StringType(), required=True),        \n",
    "            NestedField(field_id=2, name=\"container_id\", field_type=StringType(), required=True),\n",
    "            NestedField(field_id=3, name=\"container_name\", field_type=StringType(), required=True),\n",
    "            NestedField(field_id=4, name=\"container_namespace\", field_type=StringType(), required=True),\n",
    "            NestedField(field_id=5, name=\"pod_name\", field_type=StringType(), required=False),\n",
    "            NestedField(field_id=6, name=\"timeUnixNano\", field_type=LongType(), required=False),\n",
    "            NestedField(field_id=7, name=\"asDouble\", field_type=StringType(), required=False),   \n",
    "        )\n",
    "        \n",
    "        partition_spec = PartitionSpec(\n",
    "            PartitionField(\n",
    "                source_id=2, field_id=1000, transform=DayTransform(), name=\"container_id\"\n",
    "            )\n",
    "        )\n",
    "        sort_order = SortOrder(SortField(source_id=1, transform=IdentityTransform()))\n",
    "\n",
    "      # Check if table exists before creating it\n",
    "        tables = catalog.list_tables(\"my_namespace_name\")\n",
    "        if \"sample_table\" not in tables:\n",
    "            table = catalog.create_table(\n",
    "                identifier=\"my_namespace_name.sample_table\",\n",
    "                schema=schema,\n",
    "                location=f\"s3a://{s3_bucket_name}/sample\",\n",
    "                partition_spec=partition_spec,\n",
    "                sort_order=sort_order\n",
    "            )\n",
    "            logger.info(\"Iceberg table 'sample_table' created successfully.\")\n",
    "        else:\n",
    "            logger.info(\"Table 'sample_table' already exists in namespace 'my_namespace_name'.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred while setting up the Iceberg table: {e}\")\n",
    "\n",
    "# setup_iceberg_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "from pyiceberg.io.pyarrow import PyArrowFileIO\n",
    "\n",
    "def write_to_iceberg(table, messages):\n",
    "     # Convert messages to PyArrow Table\n",
    "    data = {\n",
    "        \"resourceMetrics\": [json.dumps(msg) for msg in messages],  # Store the entire message as a string\n",
    "        \"container_id\": [msg.get(\"container_id\") for msg in messages],\n",
    "        \"container_name\": [msg.get(\"container_name\") for msg in messages],\n",
    "        \"container_namespace\": [msg.get(\"container_namespace\") for msg in messages],\n",
    "        \"pod_name\": [msg.get(\"pod_name\") for msg in messages],\n",
    "        \"timeUnixNano\": [msg.get(\"timeUnixNano\") for msg in messages],\n",
    "        \"asDouble\": [msg.get(\"asDouble\") for msg in messages],\n",
    "    }\n",
    "\n",
    "    arrow_table = pa.Table.from_pydict(data)\n",
    "    \n",
    "    # Write the data to the Iceberg table\n",
    "    file_io = PyArrowFileIO()\n",
    "    with table.new_append(file_io) as writer:\n",
    "        writer.add(arrow_table)\n",
    "        writer.commit()\n",
    "\n",
    "# json_responses = consume_messages(consumer)\n",
    "# table = setup_iceberg_table()        \n",
    "# write_to_iceberg(table, json_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Check if the consumer is correctly created and not None\n",
    "    if consumer is not None:\n",
    "        json_responses = consume_messages(consumer)\n",
    "        print(json_responses)\n",
    "        if json_responses:\n",
    "            table = setup_iceberg_table()\n",
    "            write_to_iceberg(table, json_responses)\n",
    "            for json_response in json_responses:\n",
    "                print(json.dumps(json_response, indent=2))  # Pretty-print JSON response\n",
    "        else:\n",
    "            logger.info(\"No messages consumed.\")\n",
    "else:\n",
    "    logger.error(\"Consumer initialization failed. Exiting...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
